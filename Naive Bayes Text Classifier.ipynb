{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02539c8b",
   "metadata": {},
   "source": [
    "# Text Classification with Naive Bayes \n",
    "# Nicholas Cruz \n",
    "# April 22, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf9b51",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we will develop a classifier using Naive Bayes methods to analyze two datasets:\n",
    "1. A transcript of the October 22, 2020 Presidential Debate between Trump and Biden, scraped from [debates.org](https://www.debates.org/voter-education/debate-transcripts/). We will study how well the classifier predicts who is speaking given new quotes.\n",
    "2. A csv containing about 25,000 movie reviews, labeled as either positive or negative. We will study how well the classifier identifies a positive or negative review given new reviews.\n",
    "\n",
    "After developing this classifier, we will identify potential shortcomings of the model.\n",
    "\n",
    "### Naive Bayes Classifier\n",
    "\n",
    "Our implementation of this Naive Bayes classifyer will use conditional probability to make predictions. If we have labels $x$ and $y$, the model will compare the conditional probabilities of the data belonging to $x$ and $y$. The label belonging to the greater value is the model's prediction. \n",
    "\n",
    "More formally, we need to find $\\max{[P(x|y),P(y|x)]}$, where $$P(x|y) = \\frac{P(x \\cap y)}{P(y)}$$\n",
    "\n",
    "$$P(y|x) = \\frac{P(y \\cap x)}{P(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16bf202",
   "metadata": {},
   "source": [
    "## Creating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2587ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for implementation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from collections import Counter\n",
    "from zipfile import ZipFile\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53429eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for testing\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import html\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74a8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def re_show(regex, text=\"\", flags=0):\n",
    "    \"\"\"\n",
    "    Displays text with the regex match highlighted.\n",
    "    \"\"\"\n",
    "    text_css = '''\"border-style: none;\n",
    "                   border-width: 0px;\n",
    "                   padding: 0px;\n",
    "                   font-size: 14px;\n",
    "                   color: darkslategray;\n",
    "                   background-color: white;\n",
    "                   white-space: pre;\n",
    "                   line-height: 20px;\"\n",
    "                   '''\n",
    "    match_css = '''\"padding: 0px 1px 0px 1px;\n",
    "                    margin: 0px 0.5px 0px 0.5px;\n",
    "                    border-style: solid;\n",
    "                    border-width: 0.5px;\n",
    "                    border-color: maroon;\n",
    "                    background-color: cornsilk;\n",
    "                    color: crimson;\"\n",
    "                    '''\n",
    "    \n",
    "    \n",
    "    r = re.compile(f\"({regex})\", flags=flags)\n",
    "    t = r.sub(fr'###START###\\1###END###', text)\n",
    "    t = html.escape(t)\n",
    "    t = t.replace(\"###START###\", f\"<span style={match_css}>\")\n",
    "    t = t.replace(\"###END###\", f\"</span>\")\n",
    "    display(HTML(f'<code style={text_css}>{t}</code>'))\n",
    "    \n",
    "def clean_string(string):    \n",
    "    bad_strings = ['\\n','.',',',';','>','/','<br']\n",
    "    for baddy in bad_strings:\n",
    "        string = string.replace(baddy,'')\n",
    "    string = string.replace('-',' ').replace('  ',' ')\n",
    "    return string    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94d94e",
   "metadata": {},
   "source": [
    "### Presidential Debates Dataframe\n",
    "\n",
    "Each row of this dataframe will be a word said in the debate, and each column will indicate how many times Biden and Trump said that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f59e719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biden</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220000</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>americans</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dead</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>if</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>83</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calls</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normally</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>together</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemployment</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diplomas</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              biden  trump\n",
       "220000            2      1\n",
       "americans         6      1\n",
       "dead              3      3\n",
       "if               21     22\n",
       "you              83    127\n",
       "...             ...    ...\n",
       "calls             1      2\n",
       "normally          1      2\n",
       "together          1      2\n",
       "unemployment      1      2\n",
       "diplomas          1      3\n",
       "\n",
       "[1933 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get debate html from web and grab div tag with debate content\n",
    "debate_url = \"https://www.debates.org/voter-education/debate-transcripts/october-22-2020-debate-transcript/\"\n",
    "debate = requests.get(debate_url).text\n",
    "debate_soup = BeautifulSoup(debate)\n",
    "debate_html = debate_soup.findAll('div',id=\"content-sm\")[0]\n",
    "\n",
    "# clean up html and turn into string\n",
    "debate_str = \"\"\n",
    "for block in debate_html.findAll('p'):\n",
    "    debate_str+=str(block)\n",
    "for tag in ['<p>','<b>','</b>','</p>','<br/>','\\n','\\xa0', '<span class=\"Apple-converted-space\">','</span>']:\n",
    "    debate_str=debate_str.replace(tag,\" \")\n",
    "\n",
    "# find all word blocks between BIDEN: and the next all caps word \n",
    "biden_blocks = re.findall(r'BIDEN:(.*?)(?=\\b[A-Z]{2,}\\b)', debate_str) \n",
    "biden_str = clean_string(' '.join(biden_blocks)).lower() # clean string\n",
    "biden_wordlist = biden_str.split() # split on white space\n",
    "biden_counter = Counter(biden_wordlist) # count words in list\n",
    "\n",
    "# find all word blocks between TRUMP: and the next all caps word \n",
    "trump_blocks = re.findall(r'TRUMP:(.*?)(?=\\b[A-Z]{2,}\\b)', debate_str)\n",
    "trump_str = clean_string(' '.join(trump_blocks)).lower() # clean string\n",
    "trump_wordlist = trump_str.split() # split on white space\n",
    "trump_counter = Counter(trump_wordlist) # count words in list\n",
    "\n",
    "debate_words_df = pd.DataFrame({'biden':biden_counter, 'trump':trump_counter}) # make dataframe from dictionary\n",
    "debate_words_df = debate_words_df.fillna(0) # address NaNs\n",
    "debate_words_df.biden = debate_words_df.biden.astype(int) # declare int type for counts\n",
    "debate_words_df.trump = debate_words_df.trump.astype(int)\n",
    "\n",
    "debate_words_df\n",
    "\n",
    "# laplace smoothing\n",
    "debate_words_df = debate_words_df.add(1)\n",
    "\n",
    "debate_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240cc3a",
   "metadata": {},
   "source": [
    "### Movie Reviews Dataframe \n",
    "\n",
    "This movie review dataframe was given in class. Because of its size, I have chosen to split the dataset in half for training and testing, rather than training on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20f13d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"movie_reviews.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "357d3b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12500/12500 [01:07<00:00, 186.05it/s]\n"
     ]
    }
   ],
   "source": [
    "counter_pos = Counter([])\n",
    "counter_neg = Counter([])\n",
    "\n",
    "# for convenience, we will split the dataset into testing and training\n",
    "X_train, X_test, y_train, y_test = train_test_split(movies['review'], \n",
    "                                                    movies['sentiment'], \n",
    "                                                    test_size=0.50, \n",
    "                                                    random_state=1)\n",
    "\n",
    "n = len(X_train)\n",
    "# clean formatting of data\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    words = movies.loc[i,'review'].lower()\n",
    "    words = clean_string(words)    \n",
    "    words = words.split(' ')\n",
    "    \n",
    "    # add to respective word counters\n",
    "    if movies.loc[i,'sentiment'] == \"positive\":\n",
    "        counter_pos += Counter(words)\n",
    "    else:\n",
    "        counter_neg += Counter(words)\n",
    "        \n",
    "review_words_df = pd.DataFrame({'positive':counter_pos, 'negative':counter_neg}) # make dataframe from dictionary\n",
    "review_words_df = review_words_df.fillna(0) # address NaNs\n",
    "review_words_df.positive = review_words_df.positive.astype(int) # declare int type for counts\n",
    "review_words_df.negative = review_words_df.negative.astype(int)\n",
    "\n",
    "# laplace smoothing\n",
    "review_words_df = review_words_df.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdbcd42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>17427</td>\n",
       "      <td>19716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>840</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>33135</td>\n",
       "      <td>34839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>2904</td>\n",
       "      <td>2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>17223</td>\n",
       "      <td>20013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goldfinger</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space\"?</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"p9fos\"</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"shampoo\"</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"town</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102591 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive  negative\n",
       "i              17427     19716\n",
       "got              840      1010\n",
       "to             33135     34839\n",
       "see             2904      2644\n",
       "this           17223     20013\n",
       "...              ...       ...\n",
       "goldfinger         1         2\n",
       "space\"?            1         2\n",
       "\"p9fos\"            1         2\n",
       "\"shampoo\"          1         2\n",
       "\"town              1         2\n",
       "\n",
       "[102591 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ee919",
   "metadata": {},
   "source": [
    "## Creating the Naive Bayes Model\n",
    "\n",
    "The model will iterate through each word of a text (excluding stop words) and calculate the conditional log probability of each word having a certain label (positive/negative for movie reviews and Biden/Trump for debates). The label of higher value is the prediction. \n",
    "\n",
    "**Note.** This implementation uses log likelihood to avoid underflow/overflow issues with floats. This means that we add probabilities where we would usually multiply them.\n",
    "\n",
    "### Model for Movie Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a75ed599",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = \"a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your\"\n",
    "stops = stops.split(',')\n",
    "\n",
    "def rev_probs(review_text):\n",
    "    value_pos_lst = [] # list of 'positive' probabilities \n",
    "    value_neg_lst = [] # list of 'negative' probabilities \n",
    "\n",
    "    words = clean_string(review_text).lower().split(' ') # clean text and split on whitespace\n",
    "    for word in words:\n",
    "        if word in stops:\n",
    "            None # handle stop words\n",
    "        else:\n",
    "            try:\n",
    "                p = review_words_df.loc[word]/review_words_df.sum() # probability that word is positive or negative \n",
    "                value_pos_lst.append(p[\"positive\"]) # append to list\n",
    "                value_neg_lst.append(p[\"negative\"]) # append to list\n",
    "            except:\n",
    "                None\n",
    "    tot = np.array(review_words_df.sum()).sum() # total amount of words said\n",
    "    prod = np.ones(2) # initialize prediction array\n",
    "    prod[0] = review_words_df['negative'].sum()/(tot) # probability of a word being negative\n",
    "    prod[1] = review_words_df['positive'].sum()/(tot) # probability of a word being positive\n",
    "    prod = np.log10(prod) # take log of probabilities to avoid underflow\n",
    "    \n",
    "    # multiply probabilities according to Naive Bayes \n",
    "    prod[0] += np.log10(value_neg_lst).sum() \n",
    "    prod[1] += np.log10(value_pos_lst).sum()\n",
    "    return prod\n",
    "\n",
    "# Display results\n",
    "def print_rev_results(prod):\n",
    "    print('log likelihood of it being negative is: '+str(prod[0]))\n",
    "    print('log likelihood of it being positive is: '+str(prod[1]))\n",
    "    if(prod[0]>prod[1]):    \n",
    "        print('\\n It\\'s most likely its negative')\n",
    "    else:\n",
    "        print('\\n It\\'s most likely its positive')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99131a66",
   "metadata": {},
   "source": [
    "### Model for Debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fec27574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deb_probs(debate_text):\n",
    "    value_biden_lst = []\n",
    "    value_trump_lst = []\n",
    "\n",
    "    words = clean_string(debate_text).lower().split(' ')\n",
    "    for word in words:\n",
    "        if word in stops:\n",
    "            None\n",
    "        else:\n",
    "            try:\n",
    "                p = debate_words_df.loc[word]/debate_words_df.sum() \n",
    "                value_biden_lst.append(p[\"biden\"])\n",
    "                value_trump_lst.append(p[\"trump\"])\n",
    "            except:\n",
    "                None\n",
    "    \n",
    "    tot = np.array(debate_words_df.sum()).sum() \n",
    "    prod = np.ones(2) \n",
    "    prod[0] = debate_words_df['trump'].sum()/(tot) \n",
    "    prod[1] = debate_words_df['biden'].sum()/(tot)\n",
    "    prod = np.log10(prod)\n",
    "    \n",
    "    prod[0] += np.log10(value_trump_lst).sum()\n",
    "    prod[1] += np.log10(value_biden_lst).sum()\n",
    "    return prod\n",
    "\n",
    "# Display results\n",
    "def print_deb_results(prod):\n",
    "    print('log likelihood of Trump speaking is: '+str(prod[0]))\n",
    "    print('log likelihood of Biden speaking is: '+str(prod[1]))\n",
    "    if(prod[0]>prod[1]):    \n",
    "        print('\\n It\\'s most likely Trump')\n",
    "    else:\n",
    "        print('\\n It\\'s most likely Biden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8731bee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log likelihood of it being negative is: -5.783843621237331\n",
      "log likelihood of it being positive is: -6.642097347854029\n",
      "\n",
      " It's most likely its negative\n",
      "\n",
      "\n",
      "log likelihood of Trump speaking is: -4.238848680362337\n",
      "log likelihood of Biden speaking is: -3.937818684698356\n",
      "\n",
      " It's most likely Biden\n"
     ]
    }
   ],
   "source": [
    "# quick check that both functions run as intended\n",
    "\n",
    "review_text = 'This movie was terrible' # I expect negative\n",
    "prod = rev_probs(review_text)\n",
    "print_rev_results(prod)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "debate_text = 'This is a bunch of malarkey' # I expect Biden\n",
    "prod = deb_probs(debate_text)\n",
    "print_deb_results(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678cbd2b",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Potential Bias in Datasets\n",
    "\n",
    "When working with both the datasets, I wondered if one label dominated the other in size. If true, how would this favor certain predictions? While conditional probability attempts to mitigate such bias by considering the size of a label, there are cases where the Naive Bayes approach is problematic. \n",
    "\n",
    "Consider the Biden vs. Trump debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0dfa1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of 'Biden' words: 8486\n",
      "Amount of 'Trump' words: 8846\n"
     ]
    }
   ],
   "source": [
    "print('Amount of \\'Biden\\' words: ' + str(debate_words_df['biden'].sum()))\n",
    "print('Amount of \\'Trump\\' words: ' + str(debate_words_df['trump'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c3349",
   "metadata": {},
   "source": [
    "Trump said more words in this specific debate, meaning Biden is not represented as accurately as Trump in the dataset. \n",
    "\n",
    "Another consequence of Trump saying more words is that common words are distributed more thinly for Trump than for Biden. Take their top 50 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8850fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trump's top 25-49 words \\n\", debate_words_df['trump'].sort_values(ascending=False)[:50], '\\n')\n",
    "print(\"Biden's top 25-49 words \\n\", debate_words_df['biden'].sort_values(ascending=False)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca0bf7",
   "metadata": {},
   "source": [
    "If we forget that many of the top 50 words are \"stop words\", Biden's top words are said more frequently than Trump's despite Trump saying more words. This means that the model works very well for words said infrequently (like \"malarkey\"), but is more likely to favor Biden for common words.\n",
    "\n",
    "This could be due to circumstance and way people communicate in general. Someone who says fewer words in a debate will have to be more concise and forward in their language, so they will naturally use more common words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249377d5",
   "metadata": {},
   "source": [
    "### The \"Naive\" in Naive Bayes\n",
    "\n",
    "The biggest flaw in the model is the assumption that words are independent of each other. Take the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dbd3ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_text = 'I do not understand why everyone thinks this movie is terrible. I enjoyed it.'\n",
    "prod = rev_probs(review_text)\n",
    "print_rev_results(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7f06c",
   "metadata": {},
   "source": [
    "The algorithm currently does not understand the context behind word usage, only the frequency of the words. A less naive model should consider patterns of words, not just the words themselves. In the above example, a more sophisticated model might see the word \"not\" and flip the labels of the subsequent words in the sentence. However, one can only hard-code language patterns so much before the model loses generality. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbacc65",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "While I am impressed by the Naive Bayes model, I do not think it is effective on written language. The \"naive\" part of the model can result in horrendously inaccurate results, since it does not consider the greater context of words in a sentence. And despite the use of conditional probability to mitigate bias, the model can still fall short when the dataset itself biases one label over another (such as when Trump speaks more during the debate). I believe we can do better when making predictive models for language. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0dc117",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. 1.9. naive Bayes. scikit. (n.d.). Retrieved April 23, 2023, from https://scikit-learn.org/stable/modules/naive_bayes.html#:~:text=Naive%20Bayes%20methods%20are%20a,value%20of%20the%20class%20variable \n",
    "\n",
    "2. Dave_Child. (2011, October 19). Regular expressions cheat sheet. Cheatography. Retrieved April 23, 2023, from https://cheatography.com/davechild/cheat-sheets/regular-expressions/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405c01c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
